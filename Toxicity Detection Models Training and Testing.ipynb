{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4JuZqsIePdr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import keras\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import string\n",
        "from collections import namedtuple\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy import sparse\n",
        "from sklearn.pipeline import make_union\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh29e80pe2aI"
      },
      "outputs": [],
      "source": [
        "# Global random state and k-fold strategy\n",
        "seed = 42\n",
        "k = 5\n",
        "cv = StratifiedKFold(n_splits=k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-basIGpe77I"
      },
      "outputs": [],
      "source": [
        "def f1_score_func(y_hat, data):\n",
        "    y_true = data.get_label()\n",
        "    y_hat = np.round(y_hat)\n",
        "    return 'f1', f1_score(y_true, y_hat), True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isKwQ6pqfLdj"
      },
      "outputs": [],
      "source": [
        "def feature_engineering(df, sparse=0):\n",
        "\n",
        "    # Comment length\n",
        "    df['length'] = df.comment_text.apply(lambda x: len(x))\n",
        "\n",
        "    # Count profanity words\n",
        "    profanity_words = ['f[u\\*]ck', 'sh[i\\*]t', 'a[s\\$]shole', 'b[i\\*]tch', 'd[i\\*]ck', 'p[u\\*]ssy', 'b[a\\*]stard', 's[l\\*]ut', 'wh[o\\*]re', 'st[u\\*]pid', 'd[u\\*]mb']\n",
        "    profanity_pattern = r'\\b(' + '|'.join(profanity_words) + r')\\b'\n",
        "    df['profanity_count'] = df.comment_text.str.findall(profanity_pattern).str.len()\n",
        "\n",
        "\n",
        "    # Capitalization percentage\n",
        "    def pct_caps(s):\n",
        "        return sum([1 for c in s if c.isupper()]) / (sum(([1 for c in s if c.isalpha()])) + 1)\n",
        "    df['caps'] = df.comment_text.apply(lambda x: pct_caps(x))\n",
        "\n",
        "    # Mean Word length\n",
        "    def word_length(s):\n",
        "        s = s.split(' ')\n",
        "        return np.mean([len(w) for w in s if w.isalpha()])\n",
        "    df['word_length'] = df.comment_text.apply(lambda x: word_length(x))\n",
        "\n",
        "    # Average number of exclamation points\n",
        "    df['exclamation'] = df.comment_text.apply(lambda s: len([c for c in s if c == '!']))\n",
        "\n",
        "    # Average number of question marks\n",
        "    df['question'] = df.comment_text.apply(lambda s: len([c for c in s if c == '?']))\n",
        "\n",
        "    # Normalize\n",
        "    for label in ['length', 'profanity_count','caps', 'word_length', 'question', 'exclamation']:\n",
        "        minimum = df[label].min()\n",
        "        diff = df[label].max() - minimum\n",
        "        df[label] = df[label].apply(lambda x: (x-minimum) / (diff))\n",
        "\n",
        "    # Strip IP Addresses\n",
        "    ip = re.compile('(([2][5][0-5]\\.)|([2][0-4][0-9]\\.)|([0-1]?[0-9]?[0-9]\\.)){3}'\n",
        "                    +'(([2][5][0-5])|([2][0-4][0-9])|([0-1]?[0-9]?[0-9]))')\n",
        "    def strip_ip(s, ip):\n",
        "        try:\n",
        "            found = ip.search(s)\n",
        "            return s.replace(found.group(), ' ')\n",
        "        except:\n",
        "            return s\n",
        "\n",
        "    df.comment_text = df.comment_text.apply(lambda x: strip_ip(x, ip))\n",
        "\n",
        "    return df\n",
        "\n",
        "def merge_features(comment_text, data, engineered_features):\n",
        "    new_features = sparse.csr_matrix(df[engineered_features].values)\n",
        "    if np.isnan(new_features.data).any():\n",
        "        new_features.data = np.nan_to_num(new_features.data)\n",
        "    return sparse.hstack([comment_text, new_features])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "XEdEF_cigGUO",
        "outputId": "28422c23-2a77-4e2d-e29c-7e765d3efb8d"
      },
      "outputs": [],
      "source": [
        "# Reset data and create holdout set.\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "targets = list(df.columns[2:])\n",
        "df_targets = df[targets].copy()\n",
        "\n",
        "df_sub = pd.read_csv('test.csv', dtype={'id': object}, na_filter=False)\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = df_sub.id.copy()\n",
        "\n",
        "# Feature Engineering\n",
        "df = feature_engineering(df)\n",
        "df_sub = feature_engineering(df_sub)\n",
        "\n",
        "print('Training labels:')\n",
        "print(list(df_targets.columns))\n",
        "print(df_targets.shape)\n",
        "\n",
        "print('\\nTraining data')\n",
        "df.drop(list(df_targets.columns), inplace=True, axis=1)\n",
        "df.drop('id', inplace=True, axis=1)\n",
        "print(list(df.columns))\n",
        "print(df.shape)\n",
        "\n",
        "\n",
        "print('\\nSubmission data')\n",
        "df_sub.drop('id', inplace=True, axis=1)\n",
        "print(list(df_sub.columns))\n",
        "print(df_sub.shape)\n",
        "\n",
        "toxic_rows = df_targets.sum(axis=1)\n",
        "toxic_rows = (toxic_rows > 0)\n",
        "targets.append('any_label')\n",
        "df_targets['any_label'] = toxic_rows.astype(int)\n",
        "\n",
        "new_features = list(df.columns[1:])\n",
        "print(new_features)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "df, holdout, df_targets, holdout_targets = train_test_split(df, df_targets, test_size=0.2, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUFiT-qHgZY0",
        "outputId": "79fa43fd-67ac-4189-8e48-ec900f41de18"
      },
      "outputs": [],
      "source": [
        "new_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Hjw2S8gcES"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import clone\n",
        "#todo\n",
        "# Weights for\n",
        "def multi_cv(model, data, labels, k=5, nb_features=False):\n",
        "    cv = StratifiedKFold(n_splits=k)\n",
        "    # Creating NB features just once from any_label has about the same\n",
        "    # performance as individual labels with faster speed.\n",
        "    def log_count_ratio(x, y):\n",
        "        x = sparse.csr_matrix(x)\n",
        "        # WARNING: Some scipy modules use indexes that start at 1!\n",
        "        # You need to add 1 to an index when performing operations on a csr_matrix\n",
        "\n",
        "        p = abs(x[np.where(y==1)].sum(axis=0))\n",
        "        p = p + 1\n",
        "        p = p / np.sum(p)\n",
        "\n",
        "        q = abs(x[np.where(y==0)].sum(axis=0))\n",
        "        q = q + 1\n",
        "        q = q / np.sum(q)\n",
        "\n",
        "        return np.log(p/q)\n",
        "\n",
        "    # Labels must be in a dataframe\n",
        "    scores = []\n",
        "    r_values = []\n",
        "    for label in labels.columns:\n",
        "        if nb_features:\n",
        "            r = log_count_ratio(data, labels[label])\n",
        "            r_values.append(r)\n",
        "            data = data.multiply(r)\n",
        "            if np.isnan(data.data).any():\n",
        "                data.data = np.nan_to_num(data.data)\n",
        "        score = np.mean(cross_val_score(clone(model), data, labels[label], scoring='f1', cv=cv))\n",
        "        print(label + ' f1 score: %.4f' % score)\n",
        "        scores.append(score)\n",
        "    print('Average (excluding any) f1 score: %.4f' % np.mean(scores[:-1]))\n",
        "    if nb_features:\n",
        "        return scores, r_values\n",
        "    else:\n",
        "        return scores\n",
        "\n",
        "#training_comments.data = np.nan_to_num(training_comments.data)\n",
        "\n",
        "#model = LinearSVC()\n",
        "#_ = multi_cv(model, training_comments, df_targets, nb_features=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRmhj6hUguUK"
      },
      "outputs": [],
      "source": [
        "class NBFeatures:\n",
        "    def __init__(self, epsilon=1, sparse=True):\n",
        "        # How much influence NB features have\n",
        "        if not epsilon > 0 and epsilon <= 1:\n",
        "            raise Exception(\"Invalid Epsilon value. Must be greater than zero and less than or equal to one.\")\n",
        "        self.epsilon = epsilon\n",
        "        self.r = None\n",
        "\n",
        "    def log_count_ratio(self, x, y):\n",
        "        x = sparse.csr_matrix(x)\n",
        "        # WARNING: Some scipy authors fall in the \"index starts at 1\" camp\n",
        "        # You need to add 1 to an index when performing operations on a csr_matrix\n",
        "        p = abs(x[np.where(y==1)].sum(axis=0))\n",
        "        p = p + 1\n",
        "        p = p / np.sum(p)\n",
        "        q = abs(x[np.where(y==0)].sum(axis=0))\n",
        "        q = q + 1\n",
        "        q = q / np.sum(q)\n",
        "        return np.log(p/q)\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self.r = self.log_count_ratio(x, y)\n",
        "\n",
        "    def transform(self, x):\n",
        "        if self.r.all()==None:\n",
        "            raise Exception(\"Model not fit, can't transform.\")\n",
        "        transformed = x.multiply(self.r)\n",
        "        return x.multiply(1-self.epsilon) + transformed.multiply(self.epsilon)\n",
        "    def fit_transform(self, x, y):\n",
        "        self.r = self.log_count_ratio(x, y)\n",
        "        return self.transform(x, y)\n",
        "\n",
        "\n",
        "#nb_trans = NBFeatures(0.5)\n",
        "#new = nb_trans.fit_transform(training_comments, np.array(df_targets.iloc[:,-1]))\n",
        "#nb_trans.r.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg0Gtycvgu5q"
      },
      "outputs": [],
      "source": [
        "def log_count_ratio(x, y):\n",
        "    x = sparse.csr_matrix(x)\n",
        "    p = abs(x[np.where(y==1)].sum(axis=0))\n",
        "    p = p + 1\n",
        "    p = p / np.sum(p)\n",
        "\n",
        "    q = abs(x[np.where(y==0)].sum(axis=0))\n",
        "    q = q + 1\n",
        "    q = q / np.sum(q)\n",
        "\n",
        "    return np.log(p/q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNYfi74egxCH",
        "outputId": "6dd49ff9-ab00-4233-d296-82df5fc13060"
      },
      "outputs": [],
      "source": [
        "comment_vector = TfidfVectorizer(max_features=10000, analyzer='word', #ngram_range=(2, 6),\n",
        "                                 stop_words='english')\n",
        "training_comments = comment_vector.fit_transform(df.comment_text)\n",
        "holdout_comments = comment_vector.transform(holdout.comment_text)\n",
        "submission_comments = comment_vector.transform(df_sub.comment_text)\n",
        "\n",
        "print(training_comments.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0qTpYP4g4xE",
        "outputId": "4b1632ef-72ee-41df-ed6b-a5efeb847dd5"
      },
      "outputs": [],
      "source": [
        "for target in targets:\n",
        "    lr = LogisticRegression(random_state=seed)\n",
        "    print(target + ' score: %.4f' % np.mean(cross_val_score(lr, merge_features(training_comments, df, new_features), df_targets[target], scoring='f1', cv=cv)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOY1Jhl1lSzO",
        "outputId": "c3ab73bc-896d-4fa4-9c79-653f842e705f"
      },
      "outputs": [],
      "source": [
        "model = MultinomialNB(alpha=1.0)\n",
        "_ = multi_cv(model, merge_features(training_comments, df, new_features), df_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G64AN79ilYyw",
        "outputId": "27d89505-a149-4c7f-cbea-562f3e35537c"
      },
      "outputs": [],
      "source": [
        "model = LinearSVC(random_state=seed)\n",
        "_ = multi_cv(model, merge_features(training_comments, df, new_features), df_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTUfwlAclm1U"
      },
      "outputs": [],
      "source": [
        "nb = NBFeatures()\n",
        "nb.fit(training_comments, df_targets.any_label)\n",
        "nb_eng = NBFeatures()\n",
        "nb_eng.fit(merge_features(training_comments, df, new_features), df_targets.any_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CR3Ybbsnex-",
        "outputId": "6ba4a464-7d85-4acf-bc3b-8ee9cd7cdb38"
      },
      "outputs": [],
      "source": [
        "#With engineered features.\n",
        "\n",
        "train_data = lgb.Dataset(merge_features(training_comments, df, new_features), label=df_targets.any_label.values)\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'verbose': 1,\n",
        "    'num_leaves': 64,\n",
        "    'n_estimators': 500,\n",
        "    'learning_rate': 0.1,\n",
        "    'max_depth': 16,\n",
        "    'n_jobs': -1,\n",
        "    'seed': seed\n",
        "}\n",
        "\n",
        "cv_results = lgb.cv(\n",
        "        params,\n",
        "        train_data,\n",
        "        num_boost_round=100,\n",
        "        nfold=5,\n",
        "        metrics='mae',\n",
        "        #early_stopping_rounds=10,\n",
        "        feval=f1_score_func\n",
        "        )\n",
        "f1_values = np.array(cv_results['valid f1-mean'])\n",
        "\n",
        "# Calculate the mean of the F1 scores.\n",
        "mean_f1 = np.mean(f1_values)\n",
        "\n",
        "print(\"Mean CV F1 score is %.4f\" % mean_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkMug98syAfm",
        "outputId": "c5245139-ccf2-4475-d254-9226e8decb0e"
      },
      "outputs": [],
      "source": [
        "comment_vector = TfidfVectorizer(max_features=30000, analyzer='word', ngram_range=(2,6),\n",
        "                                 stop_words='english')\n",
        "training_comments = comment_vector.fit_transform(df.comment_text)\n",
        "\n",
        "print(training_comments.shape)\n",
        "\n",
        "nb_eng = NBFeatures()\n",
        "nb_eng.fit(merge_features(training_comments, df, new_features), df_targets.any_label)\n",
        "training_comments = nb_eng.transform(merge_features(training_comments, df, new_features))\n",
        "\n",
        "model = LinearSVC(random_state=seed)\n",
        "\n",
        "score = np.mean(cross_val_score(model, training_comments, df_targets.any_label, scoring='f1', cv=cv))\n",
        "\n",
        "print(score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOBQNdYTyXmB",
        "outputId": "97373e74-18e0-43cf-ffc5-eae4cd3a5327"
      },
      "outputs": [],
      "source": [
        "#svm parameter tuning\n",
        "\n",
        "word_vectorizer = TfidfVectorizer(max_features=20000, analyzer='word', ngram_range=(1, 2),\n",
        "                                 stop_words='english')\n",
        "char_vectorizer = TfidfVectorizer(max_features=10000, analyzer='char', ngram_range=(3, 5),\n",
        "                                 stop_words='english')\n",
        "vectorizer = make_union(word_vectorizer, char_vectorizer, n_jobs=-1)\n",
        "training_comments = vectorizer.fit_transform(df.comment_text)\n",
        "\n",
        "print(training_comments.shape)\n",
        "\n",
        "# Reset NB feature transformer epsilon value\n",
        "nb_eng = NBFeatures()\n",
        "nb_eng.fit(merge_features(training_comments, df, new_features), df_targets.any_label)\n",
        "input_data = nb_eng.transform(merge_features(training_comments, df, new_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btIYnewsyw7n",
        "outputId": "d6a11d7e-1f6d-45de-b214-c58ce3fc494b"
      },
      "outputs": [],
      "source": [
        "#Model Evaluation Optimimum Model\n",
        "import joblib\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "word_vectorizer = TfidfVectorizer(max_features=20000, analyzer='word', ngram_range=(1, 2),\n",
        "                                 stop_words='english')\n",
        "char_vectorizer = TfidfVectorizer(max_features=10000, analyzer='char', ngram_range=(3, 5),\n",
        "                                 stop_words='english')\n",
        "vectorizer = make_union(word_vectorizer, char_vectorizer, n_jobs=-1)\n",
        "\n",
        "# Fit to and transform input data\n",
        "X_train = vectorizer.fit_transform(df.comment_text)\n",
        "X_test = vectorizer.transform(holdout.comment_text)\n",
        "\n",
        "# Name training target data\n",
        "y_train = df_targets.any_label\n",
        "y_test = holdout_targets.any_label\n",
        "\n",
        "# Create and fit NB Feature extractor\n",
        "nb = NBFeatures()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Tranform input data\n",
        "X_train = nb.transform(X_train)\n",
        "X_test = nb.transform(X_test)\n",
        "\n",
        "\n",
        "# Define model and fit to data\n",
        "model = LinearSVC(random_state=seed, C=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "joblib.dump(model, 'SVM_NB_model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLAcmH0ky6MV",
        "outputId": "f9dd74fd-492b-47f7-edfc-3d0641e5eeac"
      },
      "outputs": [],
      "source": [
        "model = joblib.load('SVM_NB_model.joblib')\n",
        "y_pred = model.predict(X_test)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "acc = (tp+tn)/(tn+fn+tp+fp)\n",
        "print(\"True Positives: %d\" % tp)\n",
        "print(\"False Positives: %d\" % fp)\n",
        "print(\"True Negatives: %d\" % tn)\n",
        "print(\"False Negatives: %d\" % fn)\n",
        "print(\"Precision: %.4f\" % (tp/(tp+fp)))\n",
        "print(\"Recall: %.4f\" % (tp/(tp+fn)))\n",
        "print(\"F1 Score: %.4f\" % f1_score(y_test, y_pred))\n",
        "print(\"Total Accuracy: %.2f%%\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "evV_QyXry8W-",
        "outputId": "057e7949-2f47-41da-b54e-eabeea6d6516"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions for the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix and F1 score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate true/false positive/negative counts\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "tn = cm[0, 0]\n",
        "fn = cm[1, 0]\n",
        "\n",
        "# Display the confusion matrix as a horizontal bar chart\n",
        "plt.barh([1, 0], [tp, tn], color='g', label='True Positive/Negative')\n",
        "plt.barh([1, 0], [fn, fp], color='r', label='False Negative/Positive')\n",
        "plt.yticks([0, 1], ['Toxic', 'Non-Toxic'])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Confusion Matrix using SVM and Naive Bayes\\n' +\n",
        "          f'{len(y_test)} Test Examples, F1 Score: {f1:.2f}')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuHOEeN2u2_w",
        "outputId": "2f1818b6-ae45-44ee-87f5-a0813862b6b9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # modified import statement\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Use pre-trained word embeddings (GloVe)\n",
        "glove_path = '/content/gdrive/MyDrive/571_Project/glove.6B.100d.txt'\n",
        "embedding_index = {}\n",
        "with open(glove_path, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = coefs\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df.comment_text)\n",
        "\n",
        "# Convert text to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(df.comment_text)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "max_len = 200\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, df_targets.any_label, test_size=0.2, random_state=seed)\n",
        "\n",
        "# Create an embedding matrix\n",
        "word_index = tokenizer.word_index\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Define the LSTM model\n",
        "with tf.distribute.MirroredStrategy().scope():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "    model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(units=64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3, batch_size=64)\n",
        "model.save('/content/gdrive/MyDrive/571_Project/my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMuzba0oSOwt",
        "outputId": "da8ab431-8125-4a12-8cfc-6a46c206183b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # modified import statement\n",
        "\n",
        "# Load the saved model\n",
        "model = tf.keras.models.load_model('/content/gdrive/MyDrive/571_Project/my_model.h5')\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df.comment_text)\n",
        "\n",
        "# Vectorize the holdout data\n",
        "holdout_vectors = vectorizer.transform(holdout.comment_text)\n",
        "\n",
        "# Pad the sequences of holdout data\n",
        "max_len = 200\n",
        "padded_holdout_sequences = pad_sequences(tokenizer.texts_to_sequences(holdout.comment_text), maxlen=max_len)\n",
        "\n",
        "# Generate binary predictions for the holdout data\n",
        "y_pred = model.predict(padded_holdout_sequences)\n",
        "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
        "\n",
        "# Print the binary predictions\n",
        "print(y_pred_binary)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgAOB6jS8qmc",
        "outputId": "a3172f7e-26c8-4536-8dd4-f1af7a520fe0"
      },
      "outputs": [],
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_binary).ravel()\n",
        "\n",
        "acc = (tp+tn)/(tn+fn+tp+fp)\n",
        "print(\"True Positives: %d\" % tp)\n",
        "print(\"False Positives: %d\" % fp)\n",
        "print(\"True Negatives: %d\" % tn)\n",
        "print(\"False Negatives: %d\" % fn)\n",
        "print(\"Precision: %.4f\" % (tp/(tp+fp)))\n",
        "print(\"Recall: %.4f\" % (tp/(tp+fn)))\n",
        "print(\"F1 Score: %.4f\" % f1_score(y_test, y_pred_binary))\n",
        "print(\"Total Accuracy: %.2f%%\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "t6X3Ks_t_cs-",
        "outputId": "8baf508e-abe5-4415-8578-5eef996e394b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the confusion matrix and F1 score\n",
        "cm = confusion_matrix(y_test, y_pred_binary)\n",
        "f1 = f1_score(y_test, y_pred_binary)\n",
        "\n",
        "# Calculate true/false positive/negative counts\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "tn = cm[0, 0]\n",
        "fn = cm[1, 0]\n",
        "\n",
        "# Display the confusion matrix as a horizontal bar chart\n",
        "plt.barh([1, 0], [tp, tn], color='g', label='True Positive/Negative')\n",
        "plt.barh([1, 0], [fn, fp], color='r', label='False Negative/Positive')\n",
        "plt.yticks([0, 1], ['Toxic', 'Non-Toxic'])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Confusion Matrix using LSTM Neural Network\\n' +\n",
        "          f'{len(y_test)} Test Examples, F1 Score: {f1:.2f}')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp20s0V9FP_m",
        "outputId": "294e99aa-a81d-435e-8541-77ad2a9fc12b"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "word_vectorizer = TfidfVectorizer(max_features=20000, analyzer='word', ngram_range=(1, 2),\n",
        "                                 stop_words='english')\n",
        "char_vectorizer = TfidfVectorizer(max_features=10000, analyzer='char', ngram_range=(3, 5),\n",
        "                                 stop_words='english')\n",
        "vectorizer = make_union(word_vectorizer, char_vectorizer, n_jobs=-1)\n",
        "\n",
        "# Fit to and transform input data\n",
        "X_train = vectorizer.fit_transform(df.comment_text)\n",
        "X_test = vectorizer.transform(holdout.comment_text)\n",
        "\n",
        "# Name training target data\n",
        "y_train = df_targets.any_label\n",
        "y_test = holdout_targets.any_label\n",
        "\n",
        "# Define model and fit to data\n",
        "model = RandomForestClassifier(random_state=seed, n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "joblib.dump(model, 'Random_Forest_model.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPgOQfu4KdUX",
        "outputId": "2e343dfd-b912-4e0f-a711-65eff87ee54d"
      },
      "outputs": [],
      "source": [
        "model = joblib.load('Random_Forest_model.joblib')\n",
        "y_pred = model.predict(X_test)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "acc = (tp+tn)/(tn+fn+tp+fp)\n",
        "print(\"True Positives: %d\" % tp)\n",
        "print(\"False Positives: %d\" % fp)\n",
        "print(\"True Negatives: %d\" % tn)\n",
        "print(\"False Negatives: %d\" % fn)\n",
        "print(\"Precision: %.4f\" % (tp/(tp+fp)))\n",
        "print(\"Recall: %.4f\" % (tp/(tp+fn)))\n",
        "print(\"F1 Score: %.4f\" % f1_score(y_test, y_pred))\n",
        "print(\"Total Accuracy: %.2f%%\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "tkRdaW5AKfaL",
        "outputId": "e6b93f10-2409-4514-c54f-db28fa51e724"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions for the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix and F1 score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate true/false positive/negative counts\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "tn = cm[0, 0]\n",
        "fn = cm[1, 0]\n",
        "\n",
        "# Display the confusion matrix as a horizontal bar chart\n",
        "plt.barh([1, 0], [tp, tn], color='g', label='True Positive/Negative')\n",
        "plt.barh([1, 0], [fn, fp], color='r', label='False Negative/Positive')\n",
        "plt.yticks([0, 1], ['Toxic', 'Non-Toxic'])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Confusion Matrix using Random Forest\\n' +\n",
        "          f'{len(y_test)} Test Examples, F1 Score: {f1:.2f}')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4817ZCkmLAkJ",
        "outputId": "91bd66d2-5f89-47c9-f304-f7dc7e6c4dfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "word_vectorizer = TfidfVectorizer(max_features=20000, analyzer='word', ngram_range=(1, 2),\n",
        "                                 stop_words='english')\n",
        "char_vectorizer = TfidfVectorizer(max_features=10000, analyzer='char', ngram_range=(3, 5),\n",
        "                                 stop_words='english')\n",
        "vectorizer = make_union(word_vectorizer, char_vectorizer, n_jobs=-1)\n",
        "\n",
        "# Fit to and transform input data\n",
        "X_train = vectorizer.fit_transform(df.comment_text)\n",
        "X_test = vectorizer.transform(holdout.comment_text)\n",
        "\n",
        "# Name training target data\n",
        "y_train = df_targets.any_label\n",
        "y_test = holdout_targets.any_label\n",
        "\n",
        "# Define model and fit to data\n",
        "model = LogisticRegression(random_state=seed, C=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "joblib.dump(model, 'Logistic_Regression_model.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TANjyAfKL-dB",
        "outputId": "833ed587-2d86-4b40-af77-2ad14309ac68"
      },
      "outputs": [],
      "source": [
        "model = joblib.load('Logistic_Regression_model.joblib')\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "acc = (tp+tn)/(tn+fn+tp+fp)\n",
        "print(\"True Positives: %d\" % tp)\n",
        "print(\"False Positives: %d\" % fp)\n",
        "print(\"True Negatives: %d\" % tn)\n",
        "print(\"False Negatives: %d\" % fn)\n",
        "print(\"Precision: %.4f\" % (tp/(tp+fp)))\n",
        "print(\"Recall: %.4f\" % (tp/(tp+fn)))\n",
        "print(\"F1 Score: %.4f\" % f1_score(y_test, y_pred))\n",
        "print(\"Total Accuracy: %.2f%%\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "YP6-Y02SME9_",
        "outputId": "afb6d749-154e-42bf-bb5a-7fd58e5a281b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions for the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix and F1 score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate true/false positive/negative counts\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "tn = cm[0, 0]\n",
        "fn = cm[1, 0]\n",
        "\n",
        "# Display the confusion matrix as a horizontal bar chart\n",
        "plt.barh([1, 0], [tp, tn], color='g', label='True Positive/Negative')\n",
        "plt.barh([1, 0], [fn, fp], color='r', label='False Negative/Positive')\n",
        "plt.yticks([0, 1], ['Toxic', 'Non-Toxic'])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Confusion Matrix using Logistic Regression\\n' +\n",
        "          f'{len(y_test)} Test Examples, F1 Score: {f1:.2f}')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
